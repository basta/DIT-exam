---
id: drs_062
course: Dynamics and Control of Networks
tags: [eigenvalue-algorithms, power-iteration, spectral-analysis]
difficulty: 3
type: open
status: to_learn
---

# Question
Describe the power method for finding leading eigenvalues and eigenvectors. What is the importance of choosing the initial seed?

## Options
A) N/A
B) N/A
C) N/A
D) N/A

---
# Solution
**Correct Answer:** The Power Method is an iterative algorithm used to find the dominant eigenvalue (the one with the largest absolute value) and its corresponding eigenvector for a given matrix $A$. The initial seed must have a non-zero component in the direction of the dominant eigenvector to ensure convergence.

## Explanation
The Power Method is a fundamental numerical technique in network science, particularly for calculating centrality measures like Eigenvector Centrality or Google's PageRank. The algorithm operates on the principle that repeatedly multiplying a vector by a matrix $A$ will cause the vector to align with the matrixâ€™s dominant eigenvector.

Suppose a matrix $A$ has $n$ linearly independent eigenvectors $v_1, v_2, \dots, v_n$ with corresponding eigenvalues $|\lambda_1| > |\lambda_2| \geq \dots \geq |\lambda_n|$. Any initial vector (seed) $b_0$ can be expressed as a linear combination of these eigenvectors:
$b_0 = c_1 v_1 + c_2 v_2 + \dots + c_n v_n$.

When we iteratively multiply $b_0$ by $A$ ($k$ times), we get:
$A^k b_0 = c_1 \lambda_1^k v_1 + c_2 \lambda_2^k v_2 + \dots + c_n \lambda_n^k v_n$.
Dividing by $\lambda_1^k$, the expression becomes:
$\frac{A^k b_0}{\lambda_1^k} = c_1 v_1 + c_2 (\frac{\lambda_2}{\lambda_1})^k v_2 + \dots$
As $k \to \infty$, the terms $(\frac{\lambda_i}{\lambda_1})^k$ approach zero because $|\lambda_1|$ is strictly greater than the other eigenvalues. Thus, the direction of the vector converges to the direction of $v_1$.

The **importance of the initial seed** lies in the coefficient $c_1$. If the initial vector $b_0$ is chosen such that it is perfectly orthogonal to the dominant eigenvector $v_1$, then $c_1 = 0$. In theoretical exact arithmetic, the algorithm would fail to find $\lambda_1$ and might instead converge to $\lambda_2$. Practical numerical applications usually avoid this because rounding errors eventually introduce a small component in the direction of $v_1$, but a "good" seed (often a vector of all ones) ensures faster and more reliable convergence.

### Steps / Derivation
1. Select an initial starting vector $b_0$ (the seed), typically with unit norm.
2. Calculate the next approximation by multiplying by $A$: $w_{k+1} = A b_k$.
3. Normalize the resulting vector to prevent numerical overflow: $b_{k+1} = \frac{w_{k+1}}{\|w_{k+1}\|}$.
4. Estimate the eigenvalue using the Rayleigh Quotient:
$$
\lambda \approx \frac{b_k^T A b_k}{b_k^T b_k}
$$
5. Repeat until the change in $b_k$ falls below a specified tolerance.

## Related Concepts
- [[eigenvector_centrality]]
- [[spectral_gap]]
- [[pagerank_algorithm]]